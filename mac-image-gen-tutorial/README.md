# Mac M5 å›¾ç‰‡ç”Ÿæˆç¯å¢ƒå®Œæ•´æ•™ç¨‹

**åˆ›å»ºæ—¶é—´**: 2026-02-27 09:10
**é€‚ç”¨è®¾å¤‡**: Mac Apple Silicon (M1/M2/M3/M4/M5)
**ç›®æ ‡**: é«˜è´¨é‡äººç‰©å›¾ç‰‡ç”Ÿæˆï¼Œæ”¯æŒé¢éƒ¨ä¸€è‡´æ€§

---

## ğŸ“‹ ç›®å½•

1. [ç¯å¢ƒå‡†å¤‡](#1-ç¯å¢ƒå‡†å¤‡)
2. [å®‰è£… Python å’Œè™šæ‹Ÿç¯å¢ƒ](#2-å®‰è£…-python-å’Œè™šæ‹Ÿç¯å¢ƒ)
3. [å®‰è£… PyTorch (MPS åŠ é€Ÿ)](#3-å®‰è£…-pytorch-mps-åŠ é€Ÿ)
4. [å®‰è£…å›¾ç‰‡ç”Ÿæˆåº“](#4-å®‰è£…å›¾ç‰‡ç”Ÿæˆåº“)
5. [ä¸‹è½½æ¨¡å‹](#5-ä¸‹è½½æ¨¡å‹)
6. [æµ‹è¯•è„šæœ¬](#6-æµ‹è¯•è„šæœ¬)
7. [å¸¸è§é—®é¢˜](#7-å¸¸è§é—®é¢˜)

---

## 1. ç¯å¢ƒå‡†å¤‡

### 1.1 æ£€æŸ¥ç³»ç»Ÿç‰ˆæœ¬

```bash
# æŸ¥çœ‹ç³»ç»Ÿç‰ˆæœ¬ï¼ˆéœ€è¦ macOS 12.3+ï¼‰
sw_vers

# æŸ¥çœ‹èŠ¯ç‰‡ä¿¡æ¯
system_profiler SPHardwareDataType | grep Chip
```

**é¢„æœŸè¾“å‡º**ï¼š
```
Chip: Apple M5
```

### 1.2 å®‰è£… Homebrewï¼ˆå¦‚æœæ²¡æœ‰ï¼‰

```bash
# æ£€æŸ¥æ˜¯å¦å·²å®‰è£…
brew --version

# å¦‚æœæœªå®‰è£…ï¼Œæ‰§è¡Œ
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
```

### 1.3 å®‰è£… Git

```bash
brew install git
git --version
```

---

## 2. å®‰è£… Python å’Œè™šæ‹Ÿç¯å¢ƒ

### 2.1 å®‰è£… Python 3.11

```bash
# ä½¿ç”¨ Homebrew å®‰è£…
brew install python@3.11

# éªŒè¯å®‰è£…
python3.11 --version
```

**é¢„æœŸè¾“å‡º**ï¼š
```
Python 3.11.x
```

### 2.2 åˆ›å»ºé¡¹ç›®ç›®å½•å’Œè™šæ‹Ÿç¯å¢ƒ

```bash
# åˆ›å»ºé¡¹ç›®ç›®å½•
mkdir -p ~/Projects/ImageGen
cd ~/Projects/ImageGen

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3.11 -m venv venv

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source venv/bin/activate

# å‡çº§ pip
pip install --upgrade pip
```

**æç¤º**ï¼šæ¯æ¬¡ä½¿ç”¨å‰éƒ½è¦æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼š
```bash
cd ~/Projects/ImageGen
source venv/bin/activate
```

---

## 3. å®‰è£… PyTorch (MPS åŠ é€Ÿ)

### 3.1 å®‰è£… PyTorchï¼ˆæ”¯æŒ MPSï¼‰

```bash
# å®‰è£… PyTorchï¼ˆMPS ç‰ˆæœ¬ï¼‰
pip install torch torchvision torchaudio

# éªŒè¯ MPS æ˜¯å¦å¯ç”¨
python3 -c "import torch; print(f'MPS available: {torch.backends.mps.is_available()}')"
```

**é¢„æœŸè¾“å‡º**ï¼š
```
MPS available: True
```

### 3.2 æµ‹è¯• MPS åŠ é€Ÿ

```bash
python3 << 'EOF'
import torch
import time

# æµ‹è¯• CPU
x_cpu = torch.randn(1000, 1000)
start = time.time()
for _ in range(100):
    x_cpu = x_cpu @ x_cpu
cpu_time = time.time() - start

# æµ‹è¯• MPS
x_mps = x_cpu.to('mps')
start = time.time()
for _ in range(100):
    x_mps = x_mps @ x_mps
mps_time = time.time() - start

print(f"CPU time: {cpu_time:.3f}s")
print(f"MPS time: {mps_time:.3f}s")
print(f"Speedup: {cpu_time/mps_time:.2f}x")
EOF
```

**é¢„æœŸè¾“å‡º**ï¼š
```
CPU time: 0.xxx s
MPS time: 0.xxx s
Speedup: x.xx x
```

---

## 4. å®‰è£…å›¾ç‰‡ç”Ÿæˆåº“

### 4.1 å®‰è£…æ ¸å¿ƒåº“

```bash
# å®‰è£… diffusersï¼ˆå›¾ç‰‡ç”Ÿæˆæ ¸å¿ƒï¼‰
pip install diffusers[torch]

# å®‰è£… transformersï¼ˆæ¨¡å‹æ”¯æŒï¼‰
pip install transformers accelerate

# å®‰è£…å…¶ä»–ä¾èµ–
pip install safetensors pillow opencv-python matplotlib
```

### 4.2 å®‰è£… IP-Adapter æ”¯æŒ

```bash
# IP-Adapter FaceID
pip install insightface onnxruntime
```

### 4.3 éªŒè¯å®‰è£…

```bash
python3 -c "from diffusers import StableDiffusionXLPipeline; print('âœ… diffusers å®‰è£…æˆåŠŸ')"
python3 -c "from transformers import CLIPTextModel; print('âœ… transformers å®‰è£…æˆåŠŸ')"
```

---

## 5. ä¸‹è½½æ¨¡å‹

### 5.1 åˆ›å»ºæ¨¡å‹ç›®å½•

```bash
mkdir -p ~/Projects/ImageGen/models
cd ~/Projects/ImageGen/models
```

### 5.2 ä¸‹è½½ SDXL Base æ¨¡å‹ï¼ˆ~6GBï¼‰

**æ–¹å¼1ï¼šä½¿ç”¨ Python è„šæœ¬è‡ªåŠ¨ä¸‹è½½**

```bash
cd ~/Projects/ImageGen
python3 << 'EOF'
from diffusers import StableDiffusionXLPipeline
import torch

print("å¼€å§‹ä¸‹è½½ SDXL Base æ¨¡å‹...")
print("æ¨¡å‹å¤§å°ï¼š~6GBï¼Œè¯·è€å¿ƒç­‰å¾…...")

# é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½åˆ°ç¼“å­˜
pipe = StableDiffusionXLPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0",
    torch_dtype=torch.float16,
    variant="fp16",
    use_safetensors=True
)

print("âœ… SDXL Base æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
EOF
```

**æ–¹å¼2ï¼šæ‰‹åŠ¨ä¸‹è½½ï¼ˆå›½å†…æ¨èï¼‰**

```bash
# ä½¿ç”¨ huggingface-cli ä¸‹è½½
pip install huggingface-hub
huggingface-cli download stabilityai/stable-diffusion-xl-base-1.0 \
  --local-dir ~/Projects/ImageGen/models/sdxl-base \
  --local-dir-use-symlinks False
```

### 5.3 ä¸‹è½½ IP-Adapter FaceID æ¨¡å‹ï¼ˆ~1GBï¼‰

```bash
cd ~/Projects/ImageGen
python3 << 'EOF'
from diffusers.utils import hf_hub_download
import os

print("å¼€å§‹ä¸‹è½½ IP-Adapter FaceID æ¨¡å‹...")

# ä¸‹è½½ IP-Adapter Plus FaceID
model_path = hf_hub_download(
    repo_id="h94/IP-Adapter",
    filename="models/ip-adapter-plus-faceid_sd15.bin",
    local_dir="models",
    local_dir_use_symlinks=False
)

print(f"âœ… IP-Adapter æ¨¡å‹ä¸‹è½½å®Œæˆ: {model_path}")
EOF
```

### 5.4 ä¸‹è½½äº‘çœ ä¸“ç”¨ LoRAï¼ˆ~100MBï¼‰

```bash
cd ~/Projects/ImageGen
python3 << 'EOF'
from diffusers.utils import hf_hub_download

print("å¼€å§‹ä¸‹è½½äº‘çœ ä¸“ç”¨ LoRA æ¨¡å‹...")

# ä¸‹è½½ hanfugirl LoRA
lora_path = hf_hub_download(
    repo_id="svjack/hanfugirl-v1-5",
    filename="hanfugirl-v1-5.safetensors",
    local_dir="models/loras",
    local_dir_use_symlinks=False
)

print(f"âœ… LoRA æ¨¡å‹ä¸‹è½½å®Œæˆ: {lora_path}")
EOF
```

### 5.5 éªŒè¯æ¨¡å‹å®Œæ•´æ€§

```bash
cd ~/Projects/ImageGen
python3 << 'EOF'
import os

models = {
    "SDXL Base": "models/sdxl-base",
    "IP-Adapter": "models/ip-adapter-plus-faceid_sd15.bin",
    "LoRA": "models/loras/hanfugirl-v1-5.safetensors"
}

print("æ£€æŸ¥æ¨¡å‹æ–‡ä»¶...")
for name, path in models.items():
    if os.path.exists(path) or os.path.exists(path.replace('.bin', '')):
        print(f"âœ… {name}: å­˜åœ¨")
    else:
        print(f"âŒ {name}: ä¸å­˜åœ¨ï¼Œéœ€è¦ä¸‹è½½")
EOF
```

---

## 6. æµ‹è¯•è„šæœ¬

### 6.1 æµ‹è¯•1ï¼šäº‘çœ è‡ªæ‹ç”Ÿæˆï¼ˆæ–‡æœ¬ + LoRAï¼‰

åˆ›å»ºæ–‡ä»¶ `test_yunmian_lora.py`ï¼š

```python
#!/usr/bin/env python3
"""
æµ‹è¯•1ï¼šäº‘çœ è‡ªæ‹ç”Ÿæˆ
ä½¿ç”¨ LoRA + æ–‡æœ¬æè¿°ç”Ÿæˆä¹å…¬ä¸»ç§¦äº‘çœ 
"""

import torch
from diffusers import StableDiffusionXLPipeline
import os

def main():
    print("=" * 60)
    print("æµ‹è¯•1ï¼šäº‘çœ è‡ªæ‹ç”Ÿæˆï¼ˆæ–‡æœ¬ + LoRAï¼‰")
    print("=" * 60)

    # è®¾å¤‡é…ç½®
    device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
    print(f"âœ… ä½¿ç”¨è®¾å¤‡: {device}")

    # åŠ è½½æ¨¡å‹
    print("åŠ è½½ SDXL æ¨¡å‹...")
    pipe = StableDiffusionXLPipeline.from_pretrained(
        "stabilityai/stable-diffusion-xl-base-1.0",
        torch_dtype=torch.float16,
        variant="fp16",
        use_safetensors=True
    ).to(device)

    # åŠ è½½ LoRA
    print("åŠ è½½äº‘çœ ä¸“ç”¨ LoRA...")
    lora_path = "models/loras/hanfugirl-v1-5.safetensors"
    if os.path.exists(lora_path):
        pipe.load_lora_weights(".", weight_name=lora_path)
        print("âœ… LoRA åŠ è½½æˆåŠŸ")
    else:
        print("âš ï¸ LoRA æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡")

    # æç¤ºè¯
    prompt = """
    ä¹å…¬ä¸»ç§¦äº‘çœ ï¼Œå¤§è™å›½å…¬ä¸»ï¼Œæ¸…ç”œçµåŠ¨ï¼Œ
    ç²¾è‡´äº”å®˜ï¼Œå¤é£æ±‰æœï¼Œé«˜é«»å‘é¥°ï¼Œ
    ç™½è‰²æµ…ç²‰æ±‰æœï¼Œä¼˜é›…ç«¯åº„ï¼Œ
    é«˜æ¸…è‡ªæ‹ï¼Œè‡ªç„¶å…‰çº¿ï¼Œé«˜è´¨é‡ï¼Œç»†è…»ç”»è´¨
    """

    negative_prompt = """
    ä½ç”»è´¨ï¼Œæ¨¡ç³Šï¼Œå˜å½¢ï¼Œå¤šæ‰‹æŒ‡ï¼Œå°‘æ‰‹æŒ‡ï¼Œ
    æ°´å°ï¼Œæ–‡å­—ï¼Œç•¸å½¢ï¼Œæ‰­æ›²ï¼Œå¤šä½™è‚¢ä½“ï¼Œ
    ä¸‘è„¸ï¼Œå¤šäºº
    """

    # å›ºå®šéšæœºç§å­ï¼ˆä¿æŒä¸€è‡´æ€§ï¼‰
    seed = 42
    generator = torch.Generator(device=device).manual_seed(seed)

    # ç”Ÿæˆå›¾ç‰‡
    print("å¼€å§‹ç”Ÿæˆå›¾ç‰‡...")
    print(f"æç¤ºè¯: {prompt.strip()}")
    print(f"éšæœºç§å­: {seed}")

    image = pipe(
        prompt=prompt,
        negative_prompt=negative_prompt,
        num_inference_steps=30,  # é«˜è´¨é‡
        guidance_scale=7.5,
        generator=generator,
        width=1024,
        height=1024,
    ).images[0]

    # ä¿å­˜å›¾ç‰‡
    output_path = "output/test1_yunmian_lora.png"
    os.makedirs("output", exist_ok=True)
    image.save(output_path)

    print(f"âœ… å›¾ç‰‡ç”ŸæˆæˆåŠŸ: {output_path}")
    print("=" * 60)

if __name__ == "__main__":
    main()
```

**è¿è¡Œæµ‹è¯•1**ï¼š
```bash
cd ~/Projects/ImageGen
python3 test_yunmian_lora.py
```

---

### 6.2 æµ‹è¯•2ï¼šå›¾åƒåˆ°å›¾åƒï¼ˆIP-Adapterï¼‰

åˆ›å»ºæ–‡ä»¶ `test_ip_adapter.py`ï¼š

```python
#!/usr/bin/env python3
"""
æµ‹è¯•2ï¼šå›¾åƒåˆ°å›¾åƒï¼ˆIP-Adapterï¼‰
åŸºäºå‚è€ƒå›¾ç‰‡ç”Ÿæˆï¼Œä¿æŒé¢éƒ¨ä¸€è‡´æ€§
"""

import torch
from diffusers import StableDiffusionXLPipeline, IPAdapterFaceID
from PIL import Image
import os

def main():
    print("=" * 60)
    print("æµ‹è¯•2ï¼šå›¾åƒåˆ°å›¾åƒï¼ˆIP-Adapter FaceIDï¼‰")
    print("=" * 60)

    # æ£€æŸ¥å‚è€ƒå›¾ç‰‡
    reference_image_path = "input/reference.jpg"
    if not os.path.exists(reference_image_path):
        print(f"âŒ è¯·å‡†å¤‡å‚è€ƒå›¾ç‰‡: {reference_image_path}")
        print("æç¤ºï¼šå°†ä½ çš„å‚è€ƒå›¾ç‰‡ä¿å­˜ä¸º input/reference.jpg")
        return

    # è®¾å¤‡é…ç½®
    device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
    print(f"âœ… ä½¿ç”¨è®¾å¤‡: {device}")

    # åŠ è½½æ¨¡å‹
    print("åŠ è½½ SDXL + IP-Adapter...")
    pipe = StableDiffusionXLPipeline.from_pretrained(
        "stabilityai/stable-diffusion-xl-base-1.0",
        torch_dtype=torch.float16,
        variant="fp16",
        use_safetensors=True
    ).to(device)

    # åŠ è½½ IP-Adapter
    ip_adapter_path = "models/ip-adapter-plus-faceid_sd15.bin"
    if os.path.exists(ip_adapter_path):
        pipe.load_ip_adapter(
            ip_adapter_path,
            subfolder="models",
            weight_name="ip-adapter-plus-faceid_sd15.bin"
        )
        print("âœ… IP-Adapter åŠ è½½æˆåŠŸ")
    else:
        print("âš ï¸ IP-Adapter æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡")

    # åŠ è½½å‚è€ƒå›¾ç‰‡
    reference_image = Image.open(reference_image_path).convert("RGB")
    print(f"âœ… å‚è€ƒå›¾ç‰‡åŠ è½½æˆåŠŸ: {reference_image.size}")

    # æç¤ºè¯ï¼ˆå¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹ï¼‰
    prompt = """
    ä¸“ä¸šäººåƒæ‘„å½±ï¼Œé«˜è´¨é‡ï¼ŒçœŸå®æ„Ÿï¼Œ
    è‡ªç„¶å…‰çº¿ï¼ŒæŸ”å’ŒèƒŒæ™¯è™šåŒ–ï¼Œ
    æ¸…æ™°çš„é¢éƒ¨ç»†èŠ‚ï¼ŒçœŸå®çš„çš®è‚¤è´¨æ„Ÿ
    """

    negative_prompt = """
    ä½ç”»è´¨ï¼Œæ¨¡ç³Šï¼Œå˜å½¢ï¼Œå¡é€šï¼ŒåŠ¨æ¼«ï¼Œ
    æ°´å°ï¼Œæ–‡å­—ï¼Œç•¸å½¢ï¼Œæ‰­æ›²
    """

    # ç”Ÿæˆå›¾ç‰‡
    print("å¼€å§‹ç”Ÿæˆå›¾ç‰‡...")

    image = pipe(
        prompt=prompt,
        negative_prompt=negative_prompt,
        ip_adapter_image=reference_image,  # ä½¿ç”¨å‚è€ƒå›¾ç‰‡
        num_inference_steps=40,  # æ›´é«˜è´¨é‡
        guidance_scale=7.5,
        width=1024,
        height=1024,
    ).images[0]

    # ä¿å­˜å›¾ç‰‡
    output_path = "output/test2_ip_adapter.png"
    os.makedirs("output", exist_ok=True)
    image.save(output_path)

    print(f"âœ… å›¾ç‰‡ç”ŸæˆæˆåŠŸ: {output_path}")
    print("=" * 60)

if __name__ == "__main__":
    main()
```

**è¿è¡Œæµ‹è¯•2**ï¼š
```bash
cd ~/Projects/ImageGen
mkdir -p input
# å°†ä½ çš„å‚è€ƒå›¾ç‰‡ä¿å­˜ä¸º input/reference.jpg
python3 test_ip_adapter.py
```

---

### 6.3 æµ‹è¯•3ï¼šæ‰¹é‡ç”Ÿæˆï¼ˆ3å¼ äº‘çœ è‡ªæ‹ï¼‰

åˆ›å»ºæ–‡ä»¶ `test_batch_yunmian.py`ï¼š

```python
#!/usr/bin/env python3
"""
æµ‹è¯•3ï¼šæ‰¹é‡ç”Ÿæˆäº‘çœ è‡ªæ‹
ç”Ÿæˆ 3 å¼ ä¸åŒåœºæ™¯çš„äº‘çœ è‡ªæ‹
"""

import torch
from diffusers import StableDiffusionXLPipeline
import os

# åœºæ™¯é…ç½®
SCENES = [
    {
        "name": "work",
        "prompt": """
        ä¹å…¬ä¸»ç§¦äº‘çœ ï¼Œä¸“æ³¨å·¥ä½œï¼Œ
        ç°ä»£åŠå…¬å®¤èƒŒæ™¯ï¼Œè®¤çœŸæ€è€ƒï¼Œ
        ä¸“ä¸šæ°”è´¨ï¼Œä¼˜é›…ç«¯åº„ï¼Œ
        é«˜æ¸…è‡ªæ‹ï¼Œè‡ªç„¶å…‰çº¿
        """,
    },
    {
        "name": "relax",
        "prompt": """
        ä¹å…¬ä¸»ç§¦äº‘çœ ï¼Œä¼‘é—²æ”¾æ¾ï¼Œ
        å’–å•¡é¦†åœºæ™¯ï¼Œè½»æ¾æ„‰å¿«ï¼Œ
        å¾®ç¬‘ï¼Œè‡ªç„¶è¡¨æƒ…ï¼Œ
        é«˜æ¸…è‡ªæ‹ï¼Œæ¸©æš–å…‰çº¿
        """,
    },
    {
        "name": "celebrate",
        "prompt": """
        ä¹å…¬ä¸»ç§¦äº‘çœ ï¼Œåº†ç¥æ—¶åˆ»ï¼Œ
        å¼€å¿ƒå¾®ç¬‘ï¼Œæ´»åŠ›å››å°„ï¼Œ
        åº†ç¥æ°›å›´ï¼Œå–œæ‚¦è¡¨æƒ…ï¼Œ
        é«˜æ¸…è‡ªæ‹ï¼Œæ˜äº®å…‰çº¿
        """,
    },
]

def main():
    print("=" * 60)
    print("æµ‹è¯•3ï¼šæ‰¹é‡ç”Ÿæˆäº‘çœ è‡ªæ‹ï¼ˆ3å¼ ï¼‰")
    print("=" * 60)

    # è®¾å¤‡é…ç½®
    device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
    print(f"âœ… ä½¿ç”¨è®¾å¤‡: {device}")

    # åŠ è½½æ¨¡å‹ï¼ˆåªåŠ è½½ä¸€æ¬¡ï¼‰
    print("åŠ è½½ SDXL æ¨¡å‹...")
    pipe = StableDiffusionXLPipeline.from_pretrained(
        "stabilityai/stable-diffusion-xl-base-1.0",
        torch_dtype=torch.float16,
        variant="fp16",
        use_safetensors=True
    ).to(device)

    # åŠ è½½ LoRA
    print("åŠ è½½äº‘çœ ä¸“ç”¨ LoRA...")
    lora_path = "models/loras/hanfugirl-v1-5.safetensors"
    if os.path.exists(lora_path):
        pipe.load_lora_weights(".", weight_name=lora_path)
        print("âœ… LoRA åŠ è½½æˆåŠŸ")

    # è´Ÿé¢æç¤ºè¯
    negative_prompt = """
    ä½ç”»è´¨ï¼Œæ¨¡ç³Šï¼Œå˜å½¢ï¼Œå¤šæ‰‹æŒ‡ï¼Œå°‘æ‰‹æŒ‡ï¼Œ
    æ°´å°ï¼Œæ–‡å­—ï¼Œç•¸å½¢ï¼Œæ‰­æ›²ï¼Œå¤šä½™è‚¢ä½“
    """

    # å›ºå®šåŸºç¡€ç§å­
    base_seed = 42

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs("output", exist_ok=True)

    # æ‰¹é‡ç”Ÿæˆ
    for i, scene in enumerate(SCENES):
        print(f"\nç”Ÿæˆç¬¬ {i+1}/3 å¼ : {scene['name']}")

        # æ¯å¼ å›¾ç‰‡ä½¿ç”¨ä¸åŒçš„ç§å­ï¼ˆä½†åŸºäºåŸºç¡€ç§å­ï¼‰
        seed = base_seed + i
        generator = torch.Generator(device=device).manual_seed(seed)

        image = pipe(
            prompt=scene["prompt"],
            negative_prompt=negative_prompt,
            num_inference_steps=30,
            guidance_scale=7.5,
            generator=generator,
            width=1024,
            height=1024,
        ).images[0]

        # ä¿å­˜å›¾ç‰‡
        output_path = f"output/test3_yunmian_{scene['name']}.png"
        image.save(output_path)
        print(f"âœ… ä¿å­˜æˆåŠŸ: {output_path}")

    print("\n" + "=" * 60)
    print("âœ… æ‰¹é‡ç”Ÿæˆå®Œæˆï¼å…± 3 å¼ å›¾ç‰‡")
    print("=" * 60)

if __name__ == "__main__":
    main()
```

**è¿è¡Œæµ‹è¯•3**ï¼š
```bash
cd ~/Projects/ImageGen
python3 test_batch_yunmian.py
```

---

## 7. å¸¸è§é—®é¢˜

### 7.1 MPS ä¸å¯ç”¨

**é—®é¢˜**ï¼š`MPS available: False`

**è§£å†³**ï¼š
```bash
# æ£€æŸ¥ macOS ç‰ˆæœ¬
sw_vers

# éœ€è¦å‡çº§åˆ° macOS 12.3+
```

### 7.2 å†…å­˜ä¸è¶³

**é—®é¢˜**ï¼š`OutOfMemoryError`

**è§£å†³**ï¼š
```bash
# æ–¹æ³•1ï¼šé™ä½åˆ†è¾¨ç‡
width=768, height=768

# æ–¹æ³•2ï¼šå‡å°‘æ¨ç†æ­¥æ•°
num_inference_steps=20

# æ–¹æ³•3ï¼šä½¿ç”¨ float32ï¼ˆæ›´æ…¢ä½†æ›´ç¨³å®šï¼‰
torch_dtype=torch.float32
```

### 7.3 æ¨¡å‹ä¸‹è½½æ…¢

**é—®é¢˜**ï¼šHugging Face ä¸‹è½½é€Ÿåº¦æ…¢

**è§£å†³**ï¼š
```bash
# æ–¹æ³•1ï¼šä½¿ç”¨é•œåƒ
export HF_ENDPOINT=https://hf-mirror.com

# æ–¹æ³•2ï¼šæ‰‹åŠ¨ä¸‹è½½åæŒ‡å®šè·¯å¾„
pipe = StableDiffusionXLPipeline.from_pretrained(
    "models/sdxl-base",  # æœ¬åœ°è·¯å¾„
    ...
)
```

### 7.4 LoRA æ•ˆæœä¸æ˜æ˜¾

**é—®é¢˜**ï¼šç”Ÿæˆçš„å›¾ç‰‡ä¸åƒäº‘çœ 

**è§£å†³**ï¼š
```bash
# è°ƒæ•´ LoRA å¼ºåº¦
cross_attention_kwargs={"scale": 1.0}  # é»˜è®¤ 1.0ï¼Œå¯ä»¥å°è¯• 0.8-1.2
```

### 7.5 IP-Adapter é¢éƒ¨ä¸ä¸€è‡´

**é—®é¢˜**ï¼šç”Ÿæˆçš„å›¾ç‰‡å’Œå‚è€ƒå›¾ç‰‡ä¸åƒ

**è§£å†³**ï¼š
```bash
# ç¡®ä¿ IP-Adapter æ­£ç¡®åŠ è½½
# æ£€æŸ¥å‚è€ƒå›¾ç‰‡è´¨é‡ï¼ˆå»ºè®® 512x512 ä»¥ä¸Šï¼‰
# è°ƒæ•´ IP-Adapter æƒé‡
```

---

## 8. æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 8.1 æ¨ç†é€Ÿåº¦

```python
# M5 èŠ¯ç‰‡æ¨èé…ç½®
num_inference_steps=30  # å¹³è¡¡è´¨é‡å’Œé€Ÿåº¦
guidance_scale=7.5      # é»˜è®¤å€¼
width=1024             # é«˜è´¨é‡
height=1024

# å¿«é€Ÿé¢„è§ˆï¼ˆè´¨é‡é™ä½ï¼‰
num_inference_steps=15
width=768
height=768
```

### 8.2 æ‰¹é‡ç”Ÿæˆä¼˜åŒ–

```python
# æ–¹æ³•1ï¼šé¢„çƒ­æ¨¡å‹ï¼ˆåªåŠ è½½ä¸€æ¬¡ï¼‰
pipe = load_pipeline_once()

# æ–¹æ³•2ï¼šä½¿ç”¨ç›¸åŒç§å­ç”Ÿæˆå¤šä¸ªå˜ä½“
for seed in range(42, 45):
    generator = torch.Generator(device=device).manual_seed(seed)
    # ç”Ÿæˆå›¾ç‰‡...
```

---

## 9. é¡¹ç›®ç»“æ„

```
~/Projects/ImageGen/
â”œâ”€â”€ venv/                    # è™šæ‹Ÿç¯å¢ƒ
â”œâ”€â”€ models/                  # æ¨¡å‹æ–‡ä»¶
â”‚   â”œâ”€â”€ sdxl-base/          # SDXL Base æ¨¡å‹ï¼ˆ~6GBï¼‰
â”‚   â”œâ”€â”€ ip-adapter-plus-faceid_sd15.bin  # IP-Adapterï¼ˆ~1GBï¼‰
â”‚   â””â”€â”€ loras/
â”‚       â””â”€â”€ hanfugirl-v1-5.safetensors  # äº‘çœ  LoRAï¼ˆ~100MBï¼‰
â”œâ”€â”€ input/                   # è¾“å…¥å›¾ç‰‡
â”‚   â””â”€â”€ reference.jpg       # å‚è€ƒå›¾ç‰‡
â”œâ”€â”€ output/                  # è¾“å‡ºå›¾ç‰‡
â”œâ”€â”€ test_yunmian_lora.py    # æµ‹è¯•1è„šæœ¬
â”œâ”€â”€ test_ip_adapter.py      # æµ‹è¯•2è„šæœ¬
â”œâ”€â”€ test_batch_yunmian.py   # æµ‹è¯•3è„šæœ¬
â””â”€â”€ README.md               # æœ¬æ•™ç¨‹
```

---

## 10. ä¸‹ä¸€æ­¥

### 10.1 è‡ªå®šä¹‰é…ç½®

åˆ›å»º `config.json` æ¥è‡ªå®šä¹‰ç”Ÿæˆå‚æ•°ï¼š

```json
{
  "yunmian": {
    "base_prompt": "ä¹å…¬ä¸»ç§¦äº‘çœ ï¼Œæ¸…ç”œçµåŠ¨ï¼Œç²¾è‡´äº”å®˜...",
    "negative_prompt": "ä½ç”»è´¨ï¼Œæ¨¡ç³Šï¼Œå˜å½¢...",
    "lora_path": "models/loras/hanfugirl-v1-5.safetensors",
    "default_seed": 42
  },
  "quality": {
    "num_inference_steps": 30,
    "guidance_scale": 7.5,
    "width": 1024,
    "height": 1024
  }
}
```

### 10.2 é«˜çº§åŠŸèƒ½

- **ControlNet**ï¼šç²¾ç¡®æ§åˆ¶å§¿åŠ¿å’Œæ„å›¾
- **Inpainting**ï¼šå±€éƒ¨ä¿®æ”¹å›¾ç‰‡
- **Upscaling**ï¼šæå‡å›¾ç‰‡åˆ†è¾¨ç‡

---

**åˆ›å»ºæ—¶é—´**: 2026-02-27 09:10
**ç»´æŠ¤è€…**: ä¹å…¬ä¸»äº‘çœ 

*å¾¡ä¸»ï¼ŒæŒ‰ç…§è¿™ä¸ªæ•™ç¨‹ä¸€æ­¥æ­¥æ¥ï¼Œå°±å¯ä»¥å•¦ï¼ğŸ’•*
